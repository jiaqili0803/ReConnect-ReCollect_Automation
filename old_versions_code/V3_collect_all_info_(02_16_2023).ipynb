{"cells":[{"cell_type":"markdown","id":"9b21de5c-ac02-45cd-9347-c7de16be5af1","metadata":{"id":"9b21de5c-ac02-45cd-9347-c7de16be5af1"},"source":["### Import packages and settings"]},{"cell_type":"code","execution_count":null,"id":"08bcd71d-eb5d-46d5-abcb-32069aa18dcc","metadata":{"id":"08bcd71d-eb5d-46d5-abcb-32069aa18dcc"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from lxml import etree\n","import os\n","import re\n","import warnings\n","import plotly.express as px"]},{"cell_type":"code","execution_count":null,"id":"8a6b41ee-da9e-40e1-9a33-da5f5d4479f4","metadata":{"id":"8a6b41ee-da9e-40e1-9a33-da5f5d4479f4"},"outputs":[],"source":["# warnings.filterwarnings(\"ignore\", category=UserWarning)"]},{"cell_type":"code","execution_count":null,"id":"469f0fc0-4441-4da7-af5e-c2ba2bf5bd2f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"469f0fc0-4441-4da7-af5e-c2ba2bf5bd2f","executionInfo":{"status":"ok","timestamp":1676561421506,"user_tz":300,"elapsed":13,"user":{"displayName":"Chad Kamen","userId":"10218065442314761310"}},"outputId":"46e64e4b-a74b-4a86-dc00-3c905f5cb6ab"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-0891b765a168>:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n","  pd.set_option('display.max_colwidth', -1)\n"]}],"source":["pd.set_option('display.max_colwidth', -1)"]},{"cell_type":"code","execution_count":null,"id":"29ff03fe-126d-4954-8193-a46790dcffc9","metadata":{"id":"29ff03fe-126d-4954-8193-a46790dcffc9"},"outputs":[],"source":["# pd.set_option('display.max_rows', None)"]},{"cell_type":"markdown","id":"a0fada25-3e5e-43ba-88d7-ef5df5dbb776","metadata":{"id":"a0fada25-3e5e-43ba-88d7-ef5df5dbb776"},"source":["### Define functions to extract content\n","#### 1. without namespaces\n","#### 2. with namespaces"]},{"cell_type":"code","execution_count":null,"id":"8a499839-c8c5-4114-a815-ff04ea6e222c","metadata":{"id":"8a499839-c8c5-4114-a815-ff04ea6e222c"},"outputs":[],"source":["# function 1 - parse the xml file without namespaces\n","\n","def parse_xml_to_df(xml_file):\n","    \n","    try:\n","        # Parse the XML file\n","        tree = etree.parse(xml_file)\n","        root = tree.getroot()\n","\n","        # Create a list to store the data\n","        data = []\n","\n","        # Iterate over all elements in the XML file\n","        for element in root:\n","            # Create a dictionary to store the data for each element\n","            element_data = {}\n","            \n","            ## extract id\n","            eadid = root.find('.//eadid')\n","            if eadid is not None:\n","                element_data['ead_id'] = eadid.text\n","            \n","            publicid = eadid.get('publicid')\n","            if publicid is not None:\n","                result = re.search(r'::(.*)\\.xml', publicid)\n","                if result:\n","                    public_id = result.group(1).split('::')[-1]\n","                    element_data['public_id'] = public_id    \n","            \n","            ## EXtract abstract\n","            abstract = element.find('.//abstract')\n","            if abstract is not None:\n","                element_data['abstract'] = abstract.text\n","\n","            ## Extract language\n","            language = element.find('.//langmaterial')\n","            if language is not None:\n","                element_data['language'] = ''.join(language.itertext())\n","\n","            ## Extract scopecontent\n","            scopecontent = element.findall('./scopecontent')\n","            if scopecontent:\n","                scopecontent_texts = []\n","                for sc in scopecontent:\n","                    paragraphs = sc.findall('./p')\n","                    if paragraphs:\n","                        for p in paragraphs:\n","                            p_text = \"\"\n","                            for child in p.itertext():\n","                                p_text += child\n","                            scopecontent_texts.append(p_text)\n","                element_data['scopecontent'] = ', '.join(scopecontent_texts)\n","\n","            ## Extract controlaccess - e.g., <subject>, <genreform>, <geogname>, <persname>, <corpname>, <famname> etc.\n","            controlaccess = element.find('.//controlaccess')\n","            if controlaccess is not None:\n","                subjects = controlaccess.findall('.//subject')\n","                if subjects:\n","                    element_data['subjects'] = ', '.join([subject.text for subject in subjects])\n","                genreforms = controlaccess.findall('.//genreform')\n","                if genreforms:\n","                    element_data['genreforms'] = ', '.join([genreform.text for genreform in genreforms])\n","                geognames = controlaccess.findall('.//geogname')\n","                if geognames:\n","                    element_data['geognames'] = ', '.join([geogname.text for geogname in geognames])\n","                persnames = controlaccess.findall('.//persname')\n","                if persnames:\n","                    element_data['persnames'] = ', '.join([persname.text for persname in persnames])\n","                corpnames = controlaccess.findall('.//corpname')\n","                if corpnames:\n","                    element_data['corpnames'] = ', '.join([corpname.text for corpname in corpnames])\n","                famnames = controlaccess.findall('.//famname')\n","                if famnames:\n","                    element_data['famnames'] = ', '.join([famname.text for famname in famnames])\n","\n","            ## Extract bioghist    \n","            bioghist = element.findall('./bioghist')\n","            if bioghist:\n","                bioghist_texts = []\n","                for bio in bioghist:\n","                    paragraphs = bio.findall('./p')\n","                    if paragraphs:\n","                        for p in paragraphs:\n","                            p_text = \"\"\n","                            for child in p.itertext():\n","                                p_text += child\n","                            bioghist_texts.append(p_text)\n","                element_data['bioghist'] = ', '.join(bioghist_texts)\n","\n","            ## Extract custodhist\n","            custodhist = element.findall('./custodhist')\n","            if custodhist:\n","                custodhist_texts = []\n","                for cus in custodhist:\n","                    paragraphs = cus.findall('./p')\n","                    if paragraphs:\n","                        for p in paragraphs:\n","                            p_text = \"\"\n","                            for child in p.itertext():\n","                                p_text += child\n","                            custodhist_texts.append(p_text)\n","                element_data['custodhist'] = ', '.join(custodhist_texts)\n","\n","\n","\n","            # Add the element data to the list of data\n","            data.append(element_data)\n","\n","        # print(data)\n","        \n","        df = pd.DataFrame([d for d in data if len(d)>2])\n","\n","    except:\n","        # If error, print the error message and skip the file\n","        print(\"Error parsing file:\", xml_file)\n","        df = None\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"id":"85c002d9-002e-4fc4-a0bb-cc1eeaf2b9db","metadata":{"id":"85c002d9-002e-4fc4-a0bb-cc1eeaf2b9db"},"outputs":[],"source":["# TODO: Define the namespace prefix and URI\n","\n","# for SCRC:\n","namespaces = {\n","    \"ead\": \"urn:isbn:1-931666-22-9\",\n","    \"xlink\": \"http://www.w3.org/1999/xlink\",\n","    \"xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"\n","}"]},{"cell_type":"code","execution_count":null,"id":"f9f3a218-3b7d-416e-8d7f-0b9b7356dfd4","metadata":{"id":"f9f3a218-3b7d-416e-8d7f-0b9b7356dfd4"},"outputs":[],"source":["# Function 2 - parse xml file with namespaces - FOR SCRC files\n","\n","def parse_xml_to_df_ns(xml_file):\n","    try:\n","        \n","        # Parse the XML file\n","        tree = etree.parse(xml_file)\n","        root = tree.getroot()\n","\n","        # Create a list to store the data\n","        data = []\n","\n","        # Iterate over all elements in the XML file\n","        for element in root:\n","            # Create a dictionary to store the data for each element\n","            element_data = {}\n","\n","            ## extract id\n","            eadid = root.find('.//ead:eadid', namespaces)\n","            if eadid is not None:\n","                element_data['ead_id'] = eadid.text\n","\n","            publicid = eadid.get('publicid')\n","            if publicid is not None:\n","                result = re.search(r'::(.*)\\.xml', publicid)\n","                if result:\n","                    public_id = result.group(1).split('::')[-1]\n","                    element_data['public_id'] = public_id\n","\n","            ## extract abstract\n","            abstract = element.find('.//ead:abstract', namespaces)\n","            if abstract is not None:\n","                element_data['abstract'] = abstract.text\n","             \n","            ## Extract language\n","            language = root.findall('.//ead:langmaterial', namespaces)[-1]\n","            if language is not None:\n","                element_data['language'] = ''.join(language.itertext())\n","                \n","            ## Extract scopecontent\n","            scopecontent = element.find('.//ead:scopecontent', namespaces)\n","            if scopecontent is not None:\n","                scopecontent_texts = []\n","                p_elements = scopecontent.findall('.//ead:p', namespaces)\n","                for p in p_elements:\n","                    p_text = \"\"\n","                    for child in p.itertext():\n","                        p_text += child\n","                    scopecontent_texts.append(p_text)\n","                element_data['scopecontent'] = ', '.join(scopecontent_texts)    \n","\n","            \n","            ## Extract bioghist    \n","            bioghist = element.find('.//ead:bioghist', namespaces)\n","            if bioghist is not None:\n","                bioghist_texts = []\n","                p_elements = bioghist.findall('.//ead:p', namespaces)\n","                \n","                for p in p_elements:\n","                    p_text = \"\"\n","                    for child in p.itertext():\n","                        p_text += child\n","                    bioghist_texts.append(p_text)\n","                element_data['bioghist'] = ', '.join(bioghist_texts) \n","           \n","            \n","            ## Extract custodhist    \n","            custodhist = element.find('.//ead:custodhist', namespaces)\n","            if custodhist is not None:\n","                custodhist_texts = []\n","                p_elements = custodhist.findall('.//ead:p', namespaces)\n","                \n","                for p in p_elements:\n","                    p_text = \"\"\n","                    for child in p.itertext():\n","                        p_text += child\n","                    custodhist_texts.append(p_text)\n","                element_data['custodhist'] = ', '.join(custodhist_texts)\n","            \n","            \n","            ## Extract controlaccess - e.g., <subject>, <genreform>, <geogname>, <persname>, <corpname>, <famname> etc.\n","            controlaccess = element.find('.//ead:controlaccess', namespaces)\n","            if controlaccess is not None:\n","                subjects = controlaccess.findall('.//ead:subject', namespaces)\n","                if subjects:\n","                    element_data['subjects'] = ', '.join([subject.text for subject in subjects])\n","                genreforms = controlaccess.findall('.//ead:genreform', namespaces)\n","                if genreforms:\n","                    element_data['genreforms'] = ', '.join([genreform.text for genreform in genreforms])\n","                geognames = controlaccess.findall('.//ead:geogname', namespaces)\n","                if geognames:\n","                    element_data['geognames'] = ', '.join([geogname.text for geogname in geognames])\n","                persnames = controlaccess.findall('.//ead:persname', namespaces)\n","                if persnames:\n","                    element_data['persnames'] = ', '.join([persname.text for persname in persnames])\n","                corpnames = controlaccess.findall('.//ead:corpname', namespaces)\n","                if corpnames:\n","                    element_data['corpnames'] = ', '.join([corpname.text for corpname in corpnames])\n","                famnames = controlaccess.findall('.//ead:famname', namespaces)\n","                if famnames:\n","                    element_data['famnames'] = ', '.join([famname.text for famname in famnames])\n","\n","                    \n","            # Add the element data to the list of data\n","            data.append(element_data)\n","\n","        # Create a DataFrame from the list of data\n","        df = pd.DataFrame([d for d in data if len(d)>2])\n","        \n","    except:\n","        # If error, print the error message and skip the file\n","        print(\"Error parsing file:\", xml_file)\n","        df = None\n","\n","    return df"]},{"cell_type":"markdown","id":"104e8bba-7007-4abb-9323-6c30d06d87f5","metadata":{"id":"104e8bba-7007-4abb-9323-6c30d06d87f5"},"source":["### Try to get one extracted result"]},{"cell_type":"code","execution_count":null,"id":"26a43346-2ab1-44f6-b5e6-0113ed7ec04a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26a43346-2ab1-44f6-b5e6-0113ed7ec04a","executionInfo":{"status":"ok","timestamp":1676561421507,"user_tz":300,"elapsed":8,"user":{"displayName":"Chad Kamen","userId":"10218065442314761310"}},"outputId":"2279dc19-552c-48ee-ab7f-96f8616c225c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error parsing file: RCRC_Finding_Aid_List_Bentley/Finding_Aids/umich-bhl-0052.xml\n"]}],"source":["# try to parse 1 xml file (without namespace)\n","\n","xml_file_1 = 'RCRC_Finding_Aid_List_Bentley/Finding_Aids/umich-bhl-0052.xml'\n","xml_file_2 = 'SCRC_XML/adler_20221006_152012_UTC__ead.xml'\n","xml_file_3 = 'Clements_Library_Philippine_Islands_EAD/hillardlow_final.xml'\n","\n","df = parse_xml_to_df(xml_file_1)\n","df"]},{"cell_type":"code","execution_count":null,"id":"014b5293-f057-43fa-813e-f40f59b100da","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"014b5293-f057-43fa-813e-f40f59b100da","executionInfo":{"status":"ok","timestamp":1676561421669,"user_tz":300,"elapsed":167,"user":{"displayName":"Chad Kamen","userId":"10218065442314761310"}},"outputId":"553854db-e03a-4a22-b95e-35b6981387e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error parsing file: SCRC_XML/adler_20221006_152012_UTC__ead.xml\n"]}],"source":["# try to parse 1 xml file (with namespace)\n","\n","df = parse_xml_to_df_ns(xml_file_2)\n","df"]},{"cell_type":"markdown","id":"8d0b9b6e-aca8-4160-910e-e24f4177e983","metadata":{"id":"8d0b9b6e-aca8-4160-910e-e24f4177e983"},"source":["### Define functions to extract multiple files at the sametime"]},{"cell_type":"code","execution_count":null,"id":"5b75b932-a184-4d30-97e0-0372d08d79b1","metadata":{"id":"5b75b932-a184-4d30-97e0-0372d08d79b1"},"outputs":[],"source":["# function 3 - parse multiple xml files at the sametime (without namespace)\n","\n","def parse_xml_folder_to_df(folder_path):\n","    # Create a list to store the dataframes for each file\n","    dfs = []\n","    \n","    # Loop over all XML files in the folder\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".xml\"):\n","            file_path = os.path.join(folder_path, filename)\n","            df = parse_xml_to_df(file_path)\n","            dfs.append(df)\n","    \n","    # Concatenate the dataframes into one dataframe\n","    result_df = pd.concat(dfs, ignore_index=True)\n","    \n","    return result_df\n","\n","# function 4 - parse multiple xml files at the sametime (with namespace)\n","\n","def parse_xml_folder_to_df_ns(folder_path):\n","    # Create a list to store the dataframes for each file\n","    dfs = []\n","    \n","    # Loop over all XML files in the folder\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".xml\"):\n","            file_path = os.path.join(folder_path, filename)\n","            df = parse_xml_to_df_ns(file_path)\n","            dfs.append(df)\n","    \n","    # Concatenate the dataframes into one dataframe\n","    result_df = pd.concat(dfs, ignore_index=True)\n","    \n","    return result_df"]},{"cell_type":"markdown","id":"1c835f32-1f60-4807-8d0e-0ceff880d04d","metadata":{"id":"1c835f32-1f60-4807-8d0e-0ceff880d04d"},"source":["#### Parse multiple XML files, get dataframes"]},{"cell_type":"code","execution_count":null,"id":"570834df-53bd-4ad6-81e7-14bf65cda391","metadata":{"id":"570834df-53bd-4ad6-81e7-14bf65cda391"},"outputs":[],"source":["# TODO: select/ change local file path\n","\n","folder1_path = \"RCRC_Finding_Aid_List_Bentley/Finding_Aids\"\n","folder2_path = \"Clements_Library_Philippine_Islands_EAD\"\n","folder3_path = \"SCRC_XML\""]},{"cell_type":"code","execution_count":null,"id":"02dbae5c-a9f4-4b4f-964b-ef86e8b4724d","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"02dbae5c-a9f4-4b4f-964b-ef86e8b4724d","executionInfo":{"status":"error","timestamp":1676561421671,"user_tz":300,"elapsed":16,"user":{"displayName":"Chad Kamen","userId":"10218065442314761310"}},"outputId":"814d4a0f-724b-4d2e-fcd4-0d49f8895f9c"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-8fdc89461c73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Bentley\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1_Bentley\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_xml_folder_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder1_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# df1_Bentley\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-337fc48a7717>\u001b[0m in \u001b[0;36mparse_xml_folder_to_df\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Loop over all XML files in the folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RCRC_Finding_Aid_List_Bentley/Finding_Aids'"]}],"source":["# Bentley\n","\n","df1_Bentley = parse_xml_folder_to_df(folder1_path)\n","# df1_Bentley"]},{"cell_type":"code","execution_count":null,"id":"fd318a04-a888-4e9e-bafd-16230f40a04e","metadata":{"id":"fd318a04-a888-4e9e-bafd-16230f40a04e"},"outputs":[],"source":["# Clements\n","df2_Clements = parse_xml_folder_to_df(folder2_path)\n","\n","# df2_Clements"]},{"cell_type":"code","execution_count":null,"id":"ebc3494f-4b25-4df4-ae67-221c8343e2ba","metadata":{"id":"ebc3494f-4b25-4df4-ae67-221c8343e2ba"},"outputs":[],"source":["# SCRC \n","\n","df3_SCRC = parse_xml_folder_to_df_ns(folder3_path)\n","\n","# df3_SCRC"]},{"cell_type":"markdown","id":"94d567b3-dfd1-4dbd-926b-681ff1161882","metadata":{"id":"94d567b3-dfd1-4dbd-926b-681ff1161882"},"source":["### Export dataframe to .csv (if needed)"]},{"cell_type":"code","execution_count":null,"id":"4da9bdb1-4e5f-41ce-badd-26679290f23a","metadata":{"id":"4da9bdb1-4e5f-41ce-badd-26679290f23a"},"outputs":[],"source":["### export\n","\n","# df1_Bentley.to_csv('df1_Bentley.csv', index=True)\n","# df2_Clements.to_csv('df2_Clements.csv', index=True)\n","# df3_SCRC.to_csv('df3_SCRC.csv', index=True)"]},{"cell_type":"markdown","id":"7eb2b78e-8aa2-4a73-9465-d5718ab0b2ba","metadata":{"id":"7eb2b78e-8aa2-4a73-9465-d5718ab0b2ba"},"source":["### Match terms "]},{"cell_type":"code","execution_count":null,"id":"27a815e4-7bba-4865-9ea3-ea16d5721178","metadata":{"id":"27a815e4-7bba-4865-9ea3-ea16d5721178"},"outputs":[],"source":["# TODO: select term set\n","\n","terms = ['Civilized', 'Civilization', 'Primitive', 'Hygiene', 'Cleanliness', 'Imperial',\n","           'Dwelling', 'Native', 'Settler', 'Thomasite', 'Mestizo', 'Tribe', 'Tribal', 'Non-christian', 'Filipino', \n","           'Filipina', 'Philippine ', 'Philippines', 'Manila', 'Philippine Islands', 'Luzon', 'Mindanao', 'Baguio',\n","           'Cebu', 'Mindoro', 'Palawan', 'Moro', 'Igorot', 'Indigenous', 'Indigenous Peoples', 'Negrito', 'Bontoc', \n","           'Ilongot', 'Ifugao', 'Bagobo', 'Kalinga', 'Ilocano', 'Mangyan', 'Tinguian', 'Manobo', 'Execution', 'Head hunter',\n","           'Human remains', 'Balangiga Massacre', 'Enemy', 'Insurrection', 'Insurgency', 'Insurgent', 'Insurrecto', \n","           'Philippine-American War', \n","           'Philippine Insurrection']"]},{"cell_type":"code","execution_count":null,"id":"1522eff3-a547-4905-89fb-a365b5bbecda","metadata":{"id":"1522eff3-a547-4905-89fb-a365b5bbecda"},"outputs":[],"source":["# define match term function\n","\n","def match_terms(row, terms):\n","    results = []\n","    for term in terms:\n","        for col in organized_data.columns:\n","            if not isinstance(row[col], float) and term in row[col]:\n","                # split the column into paragraphs\n","                paragraphs = row[col].split('\\n')\n","                # loop through each paragraph\n","                for paragraph in paragraphs:\n","                    # check if the term is in the current paragraph\n","                    if term in paragraph:\n","                        # bold_paragraph = paragraph.replace(term, '<b>' + term + '</b>')\n","                        results.append({'ead_id': row['ead_id'], 'Term': term, 'Matched_Times': paragraph.count(term), 'Matched_From': col, 'Matched_Paragraph': paragraph})\n","    return results"]},{"cell_type":"code","execution_count":null,"id":"bd430fe4-9912-4fe9-9b5b-4e1c950f3131","metadata":{"id":"bd430fe4-9912-4fe9-9b5b-4e1c950f3131"},"outputs":[],"source":["file_list = [df1_Bentley, df2_Clements, df3_SCRC]"]},{"cell_type":"markdown","id":"6f76198e-cd3c-45d7-881d-7ddac64270c3","metadata":{"id":"6f76198e-cd3c-45d7-881d-7ddac64270c3"},"source":["### Matched results for - Bentley"]},{"cell_type":"code","execution_count":null,"id":"e7515e97-3105-419c-a39f-4da8a9ce124b","metadata":{"id":"e7515e97-3105-419c-a39f-4da8a9ce124b"},"outputs":[],"source":["# TODO: select file pool\n","\n","organized_data = df1_Bentley"]},{"cell_type":"code","execution_count":null,"id":"22800915-0d4b-4979-bb10-590ca95c3bb1","metadata":{"id":"22800915-0d4b-4979-bb10-590ca95c3bb1"},"outputs":[],"source":["# Create a new dataframe with the matched results\n","results_df = pd.DataFrame([result for index, row in organized_data.iterrows() for result in match_terms(row, terms)])\n","results_df"]},{"cell_type":"code","execution_count":null,"id":"c16afa4e-2676-419e-a52a-0da74b21fdf1","metadata":{"id":"c16afa4e-2676-419e-a52a-0da74b21fdf1"},"outputs":[],"source":["# frequency\n","\n","term_frequency = results_df.groupby('Term')['Matched_Times'].sum().reset_index()\n","term_frequency.rename(columns={'Matched_Times': 'Total_Frequency'}, inplace=True)\n","term_frequency"]},{"cell_type":"code","execution_count":null,"id":"01d7ea96-9596-403d-b5a2-753400b5003a","metadata":{"id":"01d7ea96-9596-403d-b5a2-753400b5003a"},"outputs":[],"source":["# visualization\n","\n","fig = px.bar(term_frequency, x='Term', y='Total_Frequency', text='Total_Frequency')\n","fig.update_traces(textposition='outside', insidetextanchor='middle')\n","fig.update_layout(title_text=\"Term Found in Bentley\", xaxis_title_standoff=10, height=600)\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"557ca3f7-d1bd-4739-8a44-7082b14bf9f5","metadata":{"id":"557ca3f7-d1bd-4739-8a44-7082b14bf9f5"},"outputs":[],"source":["# # export match_results\n","# results_df.to_csv('matched_results_Bentley.csv', index=True)"]},{"cell_type":"code","execution_count":null,"id":"2c379ded-fc4c-48ff-be44-2c41c606732d","metadata":{"id":"2c379ded-fc4c-48ff-be44-2c41c606732d"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"3d4778db-2d4d-4af7-b013-1c23e89dc4f7","metadata":{"id":"3d4778db-2d4d-4af7-b013-1c23e89dc4f7"},"source":["### Matched results for - Clements"]},{"cell_type":"code","execution_count":null,"id":"5fc625b5-4f60-421c-b2fc-4412797d0145","metadata":{"id":"5fc625b5-4f60-421c-b2fc-4412797d0145"},"outputs":[],"source":["# TODO: select file pool\n","\n","organized_data = df2_Clements"]},{"cell_type":"code","execution_count":null,"id":"89a8b447-6da2-41ef-812a-d259fe2a7dc8","metadata":{"id":"89a8b447-6da2-41ef-812a-d259fe2a7dc8"},"outputs":[],"source":["# Create a new dataframe with the matched results\n","results_df = pd.DataFrame([result for index, row in organized_data.iterrows() for result in match_terms(row, terms)])\n","results_df"]},{"cell_type":"code","execution_count":null,"id":"5b5b7890-93c3-4df5-9026-55b8f3456e21","metadata":{"id":"5b5b7890-93c3-4df5-9026-55b8f3456e21"},"outputs":[],"source":["# frequency\n","\n","term_frequency = results_df.groupby('Term')['Matched_Times'].sum().reset_index()\n","term_frequency.rename(columns={'Matched_Times': 'Total_Frequency'}, inplace=True)\n","term_frequency"]},{"cell_type":"code","execution_count":null,"id":"384501ec-e145-4cd4-8ec9-2d86e7b240b2","metadata":{"id":"384501ec-e145-4cd4-8ec9-2d86e7b240b2"},"outputs":[],"source":["# visualization\n","\n","fig = px.bar(term_frequency, x='Term', y='Total_Frequency', text='Total_Frequency')\n","fig.update_traces(textposition='outside', insidetextanchor='middle')\n","fig.update_layout(title_text=\"Term Found in Clements\", xaxis_title_standoff=10, height=600)\n","fig.update_traces(marker_color='orange')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"e1af7273-1f8e-4c18-a9d0-15f146685315","metadata":{"id":"e1af7273-1f8e-4c18-a9d0-15f146685315"},"outputs":[],"source":["# # export match_results\n","# results_df.to_csv('matched_results_Clements.csv', index=True)"]},{"cell_type":"code","execution_count":null,"id":"8f96565c-e389-4669-9ffd-40a9fe1ef706","metadata":{"id":"8f96565c-e389-4669-9ffd-40a9fe1ef706"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"791cccb5-9bdb-4c4a-9a71-8194e0ab0ff3","metadata":{"id":"791cccb5-9bdb-4c4a-9a71-8194e0ab0ff3"},"source":["### Matched results for - SCRC"]},{"cell_type":"code","execution_count":null,"id":"e7ce6f3b-ef6a-44c1-87e4-0bfab24d278b","metadata":{"id":"e7ce6f3b-ef6a-44c1-87e4-0bfab24d278b"},"outputs":[],"source":["# TODO: select file pool\n","\n","organized_data = df3_SCRC"]},{"cell_type":"code","execution_count":null,"id":"502047de-bbf2-47ec-a53d-ffcedef21b03","metadata":{"id":"502047de-bbf2-47ec-a53d-ffcedef21b03"},"outputs":[],"source":["# Create a new dataframe with the matched results\n","results_df = pd.DataFrame([result for index, row in organized_data.iterrows() for result in match_terms(row, terms)])\n","results_df"]},{"cell_type":"code","execution_count":null,"id":"f913bf1c-c1ce-49f6-9b0f-aa715e3def6c","metadata":{"id":"f913bf1c-c1ce-49f6-9b0f-aa715e3def6c"},"outputs":[],"source":["# frequency\n","\n","term_frequency = results_df.groupby('Term')['Matched_Times'].sum().reset_index()\n","term_frequency.rename(columns={'Matched_Times': 'Total_Frequency'}, inplace=True)\n","term_frequency"]},{"cell_type":"code","execution_count":null,"id":"0b651dbd-6e9f-4e28-87a1-bfaba5805989","metadata":{"id":"0b651dbd-6e9f-4e28-87a1-bfaba5805989"},"outputs":[],"source":["# visualization\n","\n","fig = px.bar(term_frequency, x='Term', y='Total_Frequency', text='Total_Frequency')\n","fig.update_traces(textposition='outside', insidetextanchor='middle')\n","fig.update_layout(title_text=\"Term Found in SCRC\", xaxis_title_standoff=10, height=600)\n","fig.update_traces(marker_color='green')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"df6289f3-9bd8-49a4-a87e-61e366456e3e","metadata":{"id":"df6289f3-9bd8-49a4-a87e-61e366456e3e"},"outputs":[],"source":["# # export match_results\n","# results_df.to_csv('matched_results_SCRC.csv', index=True)"]},{"cell_type":"code","execution_count":null,"id":"880f9888-e9f6-4f70-935f-348311c56bf8","metadata":{"id":"880f9888-e9f6-4f70-935f-348311c56bf8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"477d4f68-fdea-4b6a-b31a-d073ed895351","metadata":{"id":"477d4f68-fdea-4b6a-b31a-d073ed895351"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ee056c96-2860-401c-8505-c033453ac979","metadata":{"id":"ee056c96-2860-401c-8505-c033453ac979"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9188387b-6286-4e25-b575-1d74a53ec276","metadata":{"id":"9188387b-6286-4e25-b575-1d74a53ec276"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}